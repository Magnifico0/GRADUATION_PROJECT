{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dabc046",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0fd57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.47.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c835d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from google.colab import drive\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "\n",
    "# Bellek yönetimi optimizasyonu\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Google Drive bağlantısı\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "\n",
    "def run_phi35_on_existing_json(image_root, input_json_path, model_path=\"microsoft/Phi-3.5-vision-instruct\"):\n",
    "    \"\"\"Mevcut JSON dosyasına Phi-3.5 sonucu ekler.\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print(\"Initializing models...\")\n",
    "    model_name = model_path.split(\"/\")[-1].lower()\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        model_path,\n",
    "        trust_remote_code=True,\n",
    "        num_crops=16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=\"auto\",\n",
    "        attn_implementation='flash_attention_2'\n",
    "    )\n",
    "\n",
    "    #Load current JSON\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for filename in tqdm([k for k in data if not k.startswith(\"_\")], desc=\"OCR process\"):\n",
    "        # Yol oluştur\n",
    "        for root, _, files in os.walk(image_root):\n",
    "            if 'text_category' in root:\n",
    "                continue\n",
    "            if filename in files:\n",
    "                img_path = os.path.join(root, filename)\n",
    "                try:\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                    prompt_message = [\n",
    "                        {\"role\": \"user\", \"content\": \"<|image_1|>\\nExtract the Turkish text from the image exactly as it appears. Do not repeat, comment, translate, or add any text. Return only the raw text. If no text is detected, return an empty response.\"}\n",
    "                    ]\n",
    "\n",
    "                    prompt = processor.tokenizer.apply_chat_template(\n",
    "                        prompt_message,\n",
    "                        tokenize=False,\n",
    "                        add_generation_prompt=True\n",
    "                    )\n",
    "\n",
    "                    inputs = processor(prompt, [image], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "                    with torch.inference_mode():\n",
    "                        generate_ids = model.generate(\n",
    "                            **inputs,\n",
    "                            max_new_tokens=512,\n",
    "                            temperature=0.0,\n",
    "                            do_sample=False,\n",
    "                            eos_token_id=processor.tokenizer.eos_token_id\n",
    "                        )\n",
    "                        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "                        extracted_text = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "                    #write OCR results\n",
    "                    data[filename][\"models\"][model_name] = {\n",
    "                        \"prediction\": extracted_text,\n",
    "                        \"cer\": None,\n",
    "                        \"wer\": None\n",
    "                    }\n",
    "\n",
    "                    del inputs, generate_ids\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"{filename} error: {str(e)}\")\n",
    "                break  \n",
    "\n",
    "       # gc.collect()\n",
    "       # torch.cuda.empty_cache()\n",
    "       # torch.cuda.synchronize()\n",
    "\n",
    "    elapsed = round(time.time() - start_time,2)\n",
    "    print(f\"\\n OCR completed: {elapsed:.2f} seconds\")\n",
    "\n",
    "    meta = data.get(\"_meta\", {})\n",
    "    processing_times = meta.get(\"processing_times\", {})\n",
    "    processing_times[model_name] = elapsed\n",
    "    meta[\"processing_times\"] = processing_times\n",
    "    data[\"_meta\"] = meta\n",
    "\n",
    "    # save updated JSON\n",
    "    with open(input_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Updated JSON saved: {input_json_path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_json_path = '/content/drive/MyDrive/nutuk/benchmark/converted_data.json'\n",
    "image_root = '/content/drive/MyDrive/nutuk/benchmark/'\n",
    "\n",
    "\n",
    "# start OCR process\n",
    "updated = run_phi35_on_existing_json(image_root, input_json_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
