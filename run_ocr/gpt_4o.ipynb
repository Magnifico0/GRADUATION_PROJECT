{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d6958",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "import base64\n",
    "import re\n",
    "from google.colab import userdata\n",
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "\n",
    "\n",
    "def run_gpt4o_on_existing_json(image_root, input_json_path, model_name='gpt4o'):\n",
    "    \"\"\"Appends GPT-4o result to existing JSON file.\"\"\"\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    api_key = userdata.get('openai')\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def encode_image(image_path):\n",
    "        \"\"\"Encode image to base64\"\"\"\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    def process_image_with_gpt(image_path, prompt):\n",
    "        \"\"\"Process image using GPT-4o\"\"\"\n",
    "        base64_image = encode_image(image_path)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        response_text = response.choices[0].message.content\n",
    "        return response_text\n",
    "\n",
    "    print(\"Initializing GPT-4o processing...\")\n",
    "\n",
    "    #Load current JSON\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    prompt = (\n",
    "        \"Extract the Turkish text from the image exactly as it appears. \"\n",
    "        \"Do not repeat, comment, translate, or add any text. \"\n",
    "        \"Return only the raw text. If no text is detected, return an empty response.\"\n",
    "    )\n",
    "\n",
    "    for filename in tqdm([k for k in data if not k.startswith(\"_\")], desc=\"OCR process\"):\n",
    "        # Yol olu≈ütur\n",
    "        for root, _, files in os.walk(image_root):\n",
    "            if 'text_category' in root:\n",
    "                continue\n",
    "            if filename in files:\n",
    "                img_path = os.path.join(root, filename)\n",
    "                try:\n",
    "                    extracted_text = process_image_with_gpt(img_path, prompt)\n",
    "\n",
    "                    #write OCR results\n",
    "                    data[filename][\"models\"][model_name] = {\n",
    "                        \"prediction\": extracted_text,\n",
    "                        \"cer\": None,\n",
    "                        \"wer\": None\n",
    "                    }\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"{filename} error: {str(e)}\")\n",
    "                break  \n",
    "    elapsed = round(time.time() - start_time,2)\n",
    "    print(f\"\\n OCR completed: {elapsed:.2f} seconds\")\n",
    "\n",
    "    meta = data.get(\"_meta\", {})\n",
    "    processing_times = meta.get(\"processing_times\", {})\n",
    "    processing_times[model_name] = elapsed\n",
    "    meta[\"processing_times\"] = processing_times\n",
    "    data[\"_meta\"] = meta\n",
    "\n",
    "    # save updated JSON\n",
    "    with open(input_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\" Updated JSON saved: {input_json_path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_json_path = '/content/drive/MyDrive/nutuk/benchmark/converted_data.json'\n",
    "image_root = '/content/drive/MyDrive/nutuk/benchmark/'\n",
    "\n",
    "\n",
    "# start OCR process\n",
    "updated = run_gpt4o_on_existing_json(image_root, input_json_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
