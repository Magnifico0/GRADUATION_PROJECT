{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f704ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from google.colab import drive\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Memory management optimization\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Google Drive connection\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "\n",
    "\n",
    "def run_trocr_on_existing_json(image_root, input_json_path, model_path = \"microsoft/trocr-large-printed\"):\n",
    "    \"\"\"Appends TrOCR result to existing JSON file.\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print(\"Initializing TrOCR model...\")\n",
    "\n",
    "    model_name = model_path.split(\"/\")[-1].lower()\n",
    "\n",
    "    # Initialize processor and model\n",
    "    processor = TrOCRProcessor.from_pretrained(model_path)\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_path).cuda()\n",
    "\n",
    "    # Load current JSON\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for filename in tqdm([k for k in data if not k.startswith(\"_\")], desc=\"OCR process\"):\n",
    "        for root, _, files in os.walk(image_root):\n",
    "            if 'text_category' in root:\n",
    "                continue\n",
    "            if filename in files:\n",
    "                img_path = os.path.join(root, filename)\n",
    "                try:\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                    # Process image\n",
    "                    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.cuda()\n",
    "\n",
    "                    # Generate text\n",
    "                    with torch.inference_mode():\n",
    "                        generated_ids = model.generate(pixel_values)\n",
    "                        extracted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "                    # Clean up\n",
    "                    del pixel_values, generated_ids\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "\n",
    "                    # Write OCR results\n",
    "                    data[filename][\"models\"][model_name] = {\n",
    "                        \"prediction\": extracted_text,\n",
    "                        \"cer\": None,\n",
    "                        \"wer\": None\n",
    "                    }\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"{filename} error: {str(e)}\")\n",
    "                break  \n",
    "\n",
    "\n",
    "\n",
    "    elapsed = round(time.time() - start_time,2)\n",
    "    print(f\"\\nðŸ•’ OCR tamamlandÄ±: {elapsed:.2f} saniye\")\n",
    "\n",
    "    meta = data.get(\"_meta\", {})\n",
    "    processing_times = meta.get(\"processing_times\", {})\n",
    "    processing_times[model_name] = elapsed\n",
    "    meta[\"processing_times\"] = processing_times\n",
    "    data[\"_meta\"] = meta\n",
    "\n",
    "    # GÃ¼ncellenmiÅŸ JSON'u kaydet\n",
    "    with open(input_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\" Updated JSON saved: {input_json_path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_json_path = '/content/drive/MyDrive/nutuk/benchmark/converted_data.json'\n",
    "image_root = '/content/drive/MyDrive/nutuk/benchmark/'\n",
    "\n",
    "\n",
    "\n",
    "# start OCR process\n",
    "updated = run_trocr_on_existing_json(image_root, input_json_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
