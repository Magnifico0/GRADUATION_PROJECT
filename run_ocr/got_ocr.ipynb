{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac02da6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 transformers==4.37.2 tiktoken==0.6.0 verovio==4.3.1 accelerate==0.28.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14ba6a",
   "metadata": {},
   "source": [
    "Solved by pip install numpy==1.26.4 --upgrade.\n",
    "Note that it needs numpy<2 otherwise raising another error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d0cf0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec71ad4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de84b4a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from google.colab import drive\n",
    "import time\n",
    "\n",
    "# Google Drive connection\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "\n",
    "def run_got_ocr_on_existing_json(image_root, input_json_path, model_path='ucaslcl/GOT-OCR2_0'):\n",
    "    \"\"\"Appends GOT-OCR result to existing JSON file.\"\"\"\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print(\"Initializing models...\")\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_path,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        use_safetensors=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    model_name = model_path.split('/')[-1].lower()\n",
    "\n",
    "    #Load current JSON\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for filename in tqdm([k for k in data if not k.startswith(\"_\")], desc=\"OCR process\"):\n",
    "        \n",
    "        for root, _, files in os.walk(image_root):\n",
    "            if 'text_category' in root:\n",
    "                continue\n",
    "            if filename in files:\n",
    "                img_path = os.path.join(root, filename)\n",
    "                try:\n",
    "                    # Get OCR result with GOT-OCR chat function\n",
    "                    extracted_text = model.chat(tokenizer, img_path, ocr_type='ocr')\n",
    "\n",
    "                    #write OCR results\n",
    "                    data[filename][\"models\"][model_name] = {\n",
    "                        \"prediction\": extracted_text,\n",
    "                        \"cer\": None,\n",
    "                        \"wer\": None\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    print(f\"{filename} error: {str(e)}\")\n",
    "                break  \n",
    "\n",
    "    elapsed = round(time.time() - start_time,2)\n",
    "    print(f\"\\n OCR completed: {elapsed:.2f} seconds\")\n",
    "\n",
    "    meta = data.get(\"_meta\", {})\n",
    "    processing_times = meta.get(\"processing_times\", {})\n",
    "    processing_times[model_name] = elapsed\n",
    "    meta[\"processing_times\"] = processing_times\n",
    "    data[\"_meta\"] = meta\n",
    "\n",
    "\n",
    "    # save updated JSON\n",
    "    with open(input_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\" Updated JSON saved: {input_json_path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_json_path = '/content/drive/MyDrive/nutuk/benchmark/converted_data.json'\n",
    "image_root = '/content/drive/MyDrive/nutuk/benchmark/'\n",
    "\n",
    "\n",
    "# start OCR process\n",
    "updated = run_got_ocr_on_existing_json(image_root, input_json_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
